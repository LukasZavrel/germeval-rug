All results on 4-fold cross-validation (number is mean of the 4 folds)

Twitter (52D) only

MULTI

0.728
test_precision_macro
0.525
test_recall_macro
0.407
test_f1_macro
0.426

-------------------------------------------------------------------------------------------------------------------------
##################         BEST       ###################################################################################
Twitter (52D) only. Sentence embedding obtained from MAX pooling on word embeddings (instead of AVERAGE pooling)

MULTI

test_accuracy
0.73
test_precision_macro
0.527
test_recall_macro
0.409
test_f1_macro
0.427

['ABUSE', 'INSULT', 'OTHER', 'PROFANITY']
[[ 474   74  473    1]
 [ 108  145  342    0]
 [ 215   63 3041    2]
 [  15    5   48    3]]


BINARY

test_accuracy
0.776
test_precision_macro
0.753
test_recall_macro
0.728
test_f1_macro
0.737

['OFFENSE', 'OTHER']
[[ 974  714]
 [ 402 2919]]


##########################################################################################################################
---------------------------------------------------------------------------------------------------------------------------

Wiki (52D) + Hate (52D) with PCA dim. reduction
Dim of final word embeddings: 52

MULTI

test_accuracy
0.727
test_precision_macro
0.523
test_recall_macro
0.406
test_f1_macro
0.424


Wiki (52D) + Hate (52D) with padding for unknown words
Dim of final word embeddings: 104

MULTI

test_accuracy
0.727
test_precision_macro
0.523
test_recall_macro
0.407
test_f1_macro
0.425


Wiki (52D) + Hate (52D) with PCA dim. reduction
Dim of final word embeddings: 52
+ extra features (Tweet len + lexicon)

MULTI

test_accuracy
0.728
test_precision_macro
0.525
test_recall_macro
0.407
test_f1_macro
0.424


Wiki (52D) + Hate (52D) + Twitter (52D) with PCA dim. reduction
Dim of final word embeddings: 52

MULTI

test_accuracy
0.728
test_precision_macro
0.525
test_recall_macro
0.406
test_f1_macro
0.424


